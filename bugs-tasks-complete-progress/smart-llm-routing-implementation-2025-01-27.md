# 🧠 Smart LLM Routing Implementation - MCP Agent

**Date**: 2025-01-27  
**Status**: ✅ **IMPLEMENTED & FIXED**  
**Priority**: High  
**Complexity**: Medium  
**Estimated Effort**: 2-3 days  

## 📋 **Problem Statement**

### **Current Architecture Issues** ✅ **RESOLVED**
The MCP agent currently connects to all MCP servers and makes all discovered tools available to the LLM via `llms.WithTools(a.Tools)`. This approach had several problems that have now been resolved:

1. **Tool Overload**: When there are >30 tools and >4 MCP servers, the LLM gets overwhelmed ✅ **FIXED**
2. **Poor Performance**: Irrelevant tools increase token usage and slow down responses ✅ **FIXED**
3. **Tool Selection Issues**: LLM may choose inappropriate tools due to information overload ✅ **FIXED**
4. **No Context Awareness**: All tools are available regardless of user query relevance ✅ **FIXED**

### **Additional Issues Discovered & Fixed**
5. **Context Truncation**: Smart routing was truncating conversation context, especially for planning agents ✅ **FIXED**
6. **Poor Tool Information**: Limited information about tool capabilities for server selection ✅ **FIXED**
7. **Orchestrator Integration**: Smart routing wasn't properly integrated with orchestrator workflow ✅ **FIXED**

### **Current Flow**
```
User Query → Connect to All Servers → Discover All Tools → Pass All Tools to LLM → LLM Response
```

### **Desired Flow**
```
User Query → Connect to All Servers → Discover All Tools → Smart Filtering → Pass Relevant Tools to LLM → LLM Response
```

## 🎯 **Solution: Smart LLM Routing**

### **Core Concept**
Implement intelligent tool filtering that uses a lightweight LLM call to determine which MCP servers and tools are most relevant to the user's query before making the main LLM call.

### **Key Benefits**
- **Performance**: Reduced token usage and faster responses
- **Accuracy**: Better tool selection by focusing on relevant capabilities  
- **Scalability**: Efficiently handles large numbers of tools
- **Configurable**: Can be enabled/disabled and thresholds adjusted
- **Fallback Safe**: Falls back to all tools if smart routing fails

## 🏗️ **Architecture Design**

### **Phase 1: Pre-Query Tool Filtering**
1. **Threshold Detection**: If tools > 30 AND servers > 4, enable smart routing
2. **LLM Pre-Call**: Make a lightweight LLM call to determine relevant servers/tools
3. **Tool Filtering**: Filter `a.Tools` to only include relevant tools before main LLM call

### **Phase 2: Implementation Components**

#### **1. Agent Configuration Options**
```go
// New agent option
func WithSmartRouting(enabled bool) AgentOption {
    return func(a *Agent) {
        a.EnableSmartRouting = enabled
    }
}

// Agent struct additions
type Agent struct {
    // ... existing fields ...
    EnableSmartRouting bool
    SmartRoutingThreshold struct {
        MaxTools    int
        MaxServers  int
    }
}
```

#### **2. Smart Routing Logic**
```go
// Smart routing detection
func (a *Agent) shouldUseSmartRouting() bool {
    return a.EnableSmartRouting && 
           len(a.Tools) > a.SmartRoutingThreshold.MaxTools &&
           len(a.Clients) > a.SmartRoutingThreshold.MaxServers
}

// Tool filtering by relevance
func (a *Agent) filterToolsByRelevance(ctx context.Context, userQuery string) ([]llms.Tool, error) {
    relevantServers := a.determineRelevantServers(ctx, userQuery)
    return a.filterToolsByServers(relevantServers), nil
}
```

#### **3. Server Relevance Determination**
```go
// Determine which servers are relevant to the user query
func (a *Agent) determineRelevantServers(ctx context.Context, userQuery string) ([]string, error) {
    prompt := a.buildServerSelectionPrompt(userQuery)
    response, err := a.makeLightweightLLMCall(ctx, prompt)
    if err != nil {
        return nil, err
    }
    return a.parseServerSelectionResponse(response), nil
}
```

#### **4. Tool Filtering Implementation**
```go
// Filter tools to only include those from relevant servers
func (a *Agent) filterToolsByServers(relevantServers []string) []llms.Tool {
    var filteredTools []llms.Tool
    
    for _, tool := range a.Tools {
        if serverName, exists := a.toolToServer[tool.Function.Name]; exists {
            for _, relevantServer := range relevantServers {
                if serverName == relevantServer {
                    filteredTools = append(filteredTools, tool)
                    break
                }
            }
        }
    }
    
    return filteredTools
}
```

## 📝 **Smart Routing Prompt Design**

### **Enhanced Server Selection Prompt Template**
```
You are a tool routing assistant. Based on the user's query and conversation context, determine which MCP servers are most relevant.

AVAILABLE MCP SERVERS:
{server_list_with_tool_counts}

CONVERSATION CONTEXT:
{conversation_context}

INSTRUCTIONS:
1. Analyze the conversation context to understand what the user is trying to accomplish
2. Identify which MCP servers contain tools that would be most helpful
3. Return ONLY the server names that are relevant, separated by commas
4. Be selective - only include servers that are clearly needed
5. If in doubt, prefer MORE servers over fewer (better to have tools available)
6. Consider the full conversation flow, not just the last message
7. Include servers that might be needed for follow-up questions
8. When uncertain, err on the side of including more servers

RESPONSE FORMAT: server1,server2,server3

RELEVANT SERVERS:
```

### **Key Prompt Enhancements**
- **Conversation Context**: Includes last 8 messages for better understanding
- **Conservative Approach**: When in doubt, includes more servers (not fewer)
- **Follow-up Consideration**: Thinks ahead to potential follow-up questions
- **Full Flow Analysis**: Considers entire conversation, not just last message
- **Tool Availability**: Prioritizes having tools available over being overly selective

### **Structured Output Schema**
```json
{
  "type": "object",
  "properties": {
    "relevant_servers": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Array of relevant MCP server names"
    },
    "reasoning": {
      "type": "string",
      "description": "Brief explanation of why these servers were selected"
    }
  },
  "required": ["relevant_servers", "reasoning"]
}
```

### **Example Structured Responses**
```json
{
  "relevant_servers": ["aws-server", "database-server", "monitoring-server"],
  "reasoning": "User is asking about AWS costs and database performance. AWS server provides cost analysis tools, database server for performance queries, and monitoring server for metrics. Including monitoring for potential follow-up questions about system health."
}
```

```json
{
  "relevant_servers": ["github-server", "kubernetes-server"],
  "reasoning": "User is asking about GitHub repository deployment and Kubernetes configuration. These two servers contain all the necessary tools for repository management and container orchestration."
}
```

### **Example Server List Format**
```
- aws-server: 15 tools
  Tools: aws_cloudwatch: Query CloudWatch metrics for monitoring data | aws_cli_query: Execute AWS CLI commands for comprehensive AWS operations | aws_s3: Manage S3 buckets and objects
- github-server: 8 tools
  Tools: clone_repository: Clone a GitHub repository locally | get_pr_info: Get detailed information about pull requests | get_repo_commit_info: Retrieve commit information from repositories
- database-server: 12 tools
  Tools: db_analyze_query: Analyze and optimize database queries | db_get_last_rows: Retrieve the most recent rows from tables | db_list_tables: List all tables in the database
- kubernetes-server: 10 tools
  Tools: k8s_list_pods: List all pods in specified namespace | k8s_kubectl_raw_command: Execute raw kubectl commands | k8s_pod_logs: Retrieve logs from Kubernetes pods
- monitoring-server: 6 tools
  Tools: grafana_query_range: Query Grafana metrics over time ranges | grafana_list_dashboards: List available Grafana dashboards | grafana_query_prometheus: Query Prometheus metrics directly
```

## 🔧 **Integration Points**

### **A. In `NewAgent()` Constructor**
```go
// Set default thresholds
ag.SmartRoutingThreshold.MaxTools = 30
ag.SmartRoutingThreshold.MaxServers = 4
ag.EnableSmartRouting = true // Default to enabled
```

### **B. In `AskWithHistory()` Conversation Flow**
```go
// Before making LLM call, check if smart routing is needed
if a.shouldUseSmartRouting() {
    // Get the full conversation history for context
    conversationContext := a.buildConversationContext(messages)
    
    filteredTools, err := a.filterToolsByRelevance(ctx, conversationContext)
    if err != nil {
        logger.Warnf("Smart routing failed, using all tools: %v", err)
        filteredTools = a.Tools // Fallback to all tools
    }
    
    // Use filtered tools instead of all tools
    opts = append(opts, llms.WithTools(filteredTools))
    logger.Infof("Smart routing enabled: using %d filtered tools out of %d total", 
                 len(filteredTools), len(a.Tools))
} else {
    // Use all tools as before
    opts = append(opts, llms.WithTools(a.Tools))
}
```

### **C. Enhanced Conversation Context Building**
```go
// Build conversation context for smart routing
func (a *Agent) buildConversationContext(messages []llms.MessageContent) string {
    var contextBuilder strings.Builder
    
    // Include more context for better routing decisions
    startIdx := 0
    if len(messages) > 8 {
        startIdx = len(messages) - 8  // Last 8 messages for better context
    }
    
    contextBuilder.WriteString("RECENT CONVERSATION:\n")
    for i := startIdx; i < len(messages); i++ {
        msg := messages[i]
        if msg.Role == llms.ChatMessageTypeHuman {
            content := a.extractTextContent(msg)
            // Truncate very long messages to avoid token bloat
            if len(content) > 200 {
                content = content[:200] + "..."
            }
            contextBuilder.WriteString(fmt.Sprintf("User: %s\n", content))
        } else if msg.Role == llms.ChatMessageTypeAI {
            content := a.extractTextContent(msg)
            if len(content) > 300 {
                content = content[:300] + "..."
            }
            contextBuilder.WriteString(fmt.Sprintf("Assistant: %s\n", content))
        }
    }
    
    return contextBuilder.String()
}
```

### **D. Lightweight LLM Call Implementation**
```go
// Make a quick LLM call for server selection
func (a *Agent) makeLightweightLLMCall(ctx context.Context, prompt string) (string, error) {
    messages := []llms.MessageContent{
        {
            Role:  llms.ChatMessageTypeSystem,
            Parts: []llms.ContentPart{llms.TextContent{Text: "You are a tool routing assistant."}},
        },
        {
            Role:  llms.ChatMessageTypeHuman,
            Parts: []llms.ContentPart{llms.TextContent{Text: prompt}},
        },
    }
    
    // Use lower temperature and max tokens for consistent routing
    opts := []llms.CallOption{
        llms.WithTemperature(0.1),
        llms.WithMaxTokens(200), // Minimal response needed
    }
    
    response, err := a.LLM.GenerateContent(ctx, messages, opts...)
    if err != nil {
        return "", err
    }
    
    return response.Choices[0].Content.Parts[0].(llms.TextContent).Text, nil
}
```

## ⚙️ **Configuration & Environment Variables**

### **Environment Variables**
```bash
# Smart routing configuration
ENABLE_SMART_ROUTING=true
SMART_ROUTING_MAX_TOOLS=30
SMART_ROUTING_MAX_SERVERS=4
SMART_ROUTING_TEMPERATURE=0.1
SMART_ROUTING_MAX_TOKENS=200
```

### **External Package Configuration**
```bash
# For external/ package usage
EXTERNAL_AGENT_SMART_ROUTING=true
EXTERNAL_AGENT_MAX_TOOLS=30
EXTERNAL_AGENT_MAX_SERVERS=4

# For LLM agent wrapper usage
LLM_AGENT_SMART_ROUTING=true
LLM_AGENT_MAX_TOOLS=30
LLM_AGENT_MAX_SERVERS=4
```

### **Agent Options**
```go
// Enable smart routing with custom thresholds
agent, err := NewAgent(ctx, llm, serverName, configPath, modelID, tracer, traceID, logger,
    WithSmartRouting(true),
    WithSmartRoutingThresholds(25, 3), // Custom thresholds
)

// Disable smart routing
agent, err := NewAgent(ctx, llm, serverName, configPath, modelID, tracer, traceID, logger,
    WithSmartRouting(false),
)
```

## 🧪 **Testing Strategy**

### **Unit Tests**
```bash
# Test smart routing detection
go test -v ./pkg/mcpagent -run TestSmartRoutingDetection

# Test tool filtering
go test -v ./pkg/mcpagent -run TestToolFiltering

# Test server relevance determination
go test -v ./pkg/mcpagent -run TestServerRelevance
```

### **Integration Tests**
```bash
# Test with many tools (>30) and servers (>4)
../bin/orchestrator test agent --comprehensive-aws --provider bedrock --smart-routing

# Test smart routing thresholds
../bin/orchestrator test smart-routing --tools-threshold 30 --servers-threshold 4

# Test fallback behavior
../bin/orchestrator test smart-routing --fallback-test

# Test external package integration
../bin/orchestrator test external --smart-routing --tools-threshold 30 --servers-threshold 4

# Test LLM agent wrapper integration
../bin/orchestrator test llm-agent --smart-routing --tools-threshold 30 --servers-threshold 4
```

### **Performance Tests**
```bash
# Compare response times with/without smart routing
../bin/orchestrator test performance --smart-routing-comparison

# Test token usage reduction
../bin/orchestrator test performance --token-usage-analysis
```

## 📊 **Metrics & Observability**

### **Event Emission Strategy (Per types-sync-design.md)**

#### **New Smart Routing Events**
```go
// Add to agent_go/pkg/mcpagent/events.go
type SmartRoutingStartEvent struct {
    BaseEventData
    TotalTools      int      `json:"total_tools"`
    TotalServers    int      `json:"total_servers"`
    Thresholds      struct {
        MaxTools    int `json:"max_tools"`
        MaxServers  int `json:"max_servers"`
    } `json:"thresholds"`
}

type SmartRoutingEndEvent struct {
    BaseEventData
    TotalTools      int      `json:"total_tools"`
    FilteredTools   int      `json:"filtered_tools"`
    TotalServers    int      `json:"total_servers"`
    RelevantServers []string `json:"relevant_servers"`
    RoutingReasoning string  `json:"routing_reasoning,omitempty"` // NEW: LLM's reasoning for server selection
    RoutingDuration time.Duration `json:"routing_duration"`
    Success         bool      `json:"success"`
    Error           string    `json:"error,omitempty"`
}
```

#### **Event Emission in Smart Routing**
```go
// In smart_routing.go, add event emission
func (a *Agent) filterToolsByRelevance(ctx context.Context, conversationContext string) ([]llms.Tool, error) {
    // Emit smart routing start event
    startEvent := NewSmartRoutingStartEvent(
        len(a.Tools), 
        len(a.Clients),
        a.SmartRoutingThreshold.MaxTools,
        a.SmartRoutingThreshold.MaxServers,
    )
    a.EmitTypedEvent(ctx, startEvent)
    
    startTime := time.Now()
    
    // Get relevant servers with reasoning
    relevantServers, reasoning, err := a.determineRelevantServersWithReasoning(ctx, conversationContext)
    if err != nil {
        // Emit failure event
        endEvent := NewSmartRoutingEndEvent(
            len(a.Tools), 0, len(a.Clients), nil, "",
            time.Since(startTime), false, err.Error(),
        )
        a.EmitTypedEvent(ctx, endEvent)
        return nil, err
    }
    
    filteredTools := a.filterToolsByServers(relevantServers)
    
    // Emit success event with reasoning
    endEvent := NewSmartRoutingEndEvent(
        len(a.Tools), len(filteredTools), len(a.Clients), relevantServers, reasoning,
        time.Since(startTime), true, "",
    )
    a.EmitTypedEvent(ctx, endEvent)
    
    return filteredTools, nil
}

// Enhanced function that returns both servers and reasoning
func (a *Agent) determineRelevantServersWithReasoning(ctx context.Context, conversationContext string) ([]string, string, error) {
    prompt := a.buildServerSelectionPrompt(conversationContext)
    return a.makeLightweightLLMCallWithReasoning(ctx, prompt)
}

// Enhanced LLM call that captures reasoning
func (a *Agent) makeLightweightLLMCallWithReasoning(ctx context.Context, prompt string) ([]string, string, error) {
    messages := []llms.MessageContent{
        {
            Role:  llms.ChatMessageTypeSystem,
            Parts: []llms.ContentPart{llms.TextContent{Text: "You are a tool routing assistant. Always respond with valid JSON."}},
        },
        {
            Role:  llms.ChatMessageTypeHuman,
            Parts: []llms.ContentPart{llms.TextContent{Text: prompt}},
        },
    }
    
    // Define the expected JSON schema for structured output
    schema := map[string]interface{}{
        "type": "object",
        "properties": map[string]interface{}{
            "relevant_servers": map[string]interface{}{
                "type": "array",
                "items": map[string]interface{}{
                    "type": "string",
                },
                "description": "Array of relevant MCP server names",
            },
            "reasoning": map[string]interface{}{
                "type": "string",
                "description": "Brief explanation of why these servers were selected",
            },
        },
        "required": []string{"relevant_servers", "reasoning"},
    }
    
    opts := []llms.CallOption{
        llms.WithTemperature(0.1),
        llms.WithMaxTokens(300),
        llms.WithStructuredOutput(schema),
    }
    
    response, err := a.LLM.GenerateContent(ctx, messages, opts...)
    if err != nil {
        return nil, "", err
    }
    
    // Parse the structured response with reasoning
    return a.parseStructuredServerResponseWithReasoning(response)
}

// Parse structured response with reasoning
func (a *Agent) parseStructuredServerResponseWithReasoning(response *llms.ContentResponse) ([]string, string, error) {
    if len(response.Choices) == 0 {
        return nil, "", fmt.Errorf("no response choices")
    }
    
    choice := response.Choices[0]
    if len(choice.Content.Parts) == 0 {
        return nil, "", fmt.Errorf("no content parts in response")
    }
    
    // Handle structured output (JSON)
    for _, part := range choice.Content.Parts {
        if jsonPart, ok := part.(llms.JSONContent); ok {
            return a.parseJSONServerResponseWithReasoning(jsonPart.Data)
        }
    }
    
    // Fallback to text parsing if structured output fails
    if len(choice.Content.Parts) > 0 {
        if textPart, ok := choice.Content.Parts[0].(llms.TextContent); ok {
            servers, err := a.parseTextServerResponse(textPart.Text)
            return servers, "Fallback text parsing used", err
        }
    }
    
    return nil, "", fmt.Errorf("unable to parse response content")
}

// Parse JSON response with reasoning
func (a *Agent) parseJSONServerResponseWithReasoning(data interface{}) ([]string, string, error) {
    dataMap, ok := data.(map[string]interface{})
    if !ok {
        return nil, "", fmt.Errorf("invalid JSON structure")
    }
    
    // Extract relevant_servers array
    serversInterface, exists := dataMap["relevant_servers"]
    if !exists {
        return nil, "", fmt.Errorf("missing 'relevant_servers' field in response")
    }
    
    serversArray, ok := serversInterface.([]interface{})
    if !ok {
        return nil, "", fmt.Errorf("'relevant_servers' is not an array")
    }
    
    // Extract reasoning
    reasoning := ""
    if reasoningInterface, exists := dataMap["reasoning"]; exists {
        if reasoningStr, ok := reasoningInterface.(string); ok {
            reasoning = reasoningStr
        }
    }
    
    // Convert to string slice
    var servers []string
    for _, server := range serversArray {
        if serverStr, ok := server.(string); ok {
            serverStr = strings.TrimSpace(serverStr)
            if serverStr != "" {
                servers = append(servers, serverStr)
            }
        }
    }
    
    return servers, reasoning, nil
}
```

#### **Event Integration Benefits**
- **Complete Observability**: Track smart routing performance and success rates
- **Performance Monitoring**: Measure routing latency and tool reduction ratios
- **Debugging Support**: Understand why certain servers were selected
- **Metrics Collection**: Gather data on routing effectiveness over time
- **Frontend Integration**: Events automatically appear in EventDispatcher for debugging

#### **Structured Output Benefits**
- **Reliable Parsing**: JSON response eliminates text parsing errors
- **Consistent Format**: Always get the expected data structure
- **Rich Information**: Includes reasoning for server selection decisions
- **Fallback Support**: Graceful degradation to text parsing if needed
- **Better Debugging**: Clear JSON structure makes troubleshooting easier

### **Metrics to Track**
- **Routing Success Rate**: Percentage of successful smart routing attempts
- **Tool Reduction Ratio**: Tools filtered out / Total tools
- **Routing Latency**: Time taken for smart routing decision
- **Fallback Rate**: How often smart routing falls back to all tools
- **Token Savings**: Tokens saved by using filtered tools

## 🔧 **Key Fixes Applied (2025-01-27)**

### **Issue 1: Context Truncation in Orchestrator Mode**
**Problem**: Smart routing was truncating conversation context, especially for planning agents, leading to poor tool selection.

**Solution Applied**:
- ✅ **Removed all message limits**: No more `maxMessages` or content truncation
- ✅ **Full context preservation**: Always sends complete conversation history
- ✅ **Universal approach**: Works for any conversation type, not just planning agents
- ✅ **Simplified logic**: Removed unnecessary orchestrator detection complexity

**Before (Broken)**:
```go
// Include more context for better routing decisions
startIdx := 0
maxMessages := a.SmartRoutingConfig.MaxMessages
if maxMessages == 0 {
    maxMessages = 8 // Fallback to default if not set
}
if len(messages) > maxMessages {
    startIdx = len(messages) - maxMessages // Last N messages for better context
}
```

**After (Fixed)**:
```go
// Always send FULL conversation context - no limits, no truncation
// This ensures smart routing has complete information for proper tool selection
contextBuilder.WriteString("FULL CONVERSATION CONTEXT:\n")

for i := 0; i < len(messages); i++ {
    // Process ALL messages with NO truncation
}
```

### **Issue 2: Poor Tool Information for Server Selection**
**Problem**: Smart routing LLM had limited information about what tools actually do, leading to poor server selection decisions.

**Solution Applied**:
- ✅ **Enhanced tool descriptions**: Include first 5 tools with descriptions for each server
- ✅ **Rich context**: Tool names + descriptions (first 100 chars) for better understanding
- ✅ **Better formatting**: Clean pipe-separated format for readability
- ✅ **Semantic understanding**: LLM can now understand tool capabilities, not just names

**Before (Basic)**:
```
- citymall-aws-mcp: 4 tools (aws_cloudwatch_filter_log_events, aws_cloudwatch, aws_cloudwatch_multi_metrics)
```

**After (Enhanced)**:
```
- citymall-aws-mcp: 4 tools
  Tools: aws_cloudwatch_filter_log_events: Filter CloudWatch log events with specific criteria | aws_cloudwatch: Query CloudWatch metrics for monitoring data | aws_cloudwatch_multi_metrics: Query multiple CloudWatch metrics simultaneously
```

### **Issue 3: Smart Routing Running on Every Turn** 🚨 **CRITICAL FIX**
**Problem**: Smart routing was being executed on **every single turn** of the conversation, making it extremely inefficient and defeating its purpose.

**Solution Applied**:
- ✅ **One-time initialization**: Smart routing now runs **ONCE** at conversation start
- ✅ **Pre-filtered tools**: Tools are filtered once and stored in `a.filteredTools`
- ✅ **Eliminated per-turn overhead**: No more LLM calls for tool selection on every turn
- ✅ **Consistent tool set**: Same filtered tools used throughout entire conversation
- ✅ **Performance improvement**: Significant reduction in latency and token usage

**Before (Broken - Every Turn)**:
```go
// This was running on EVERY turn - completely wrong!
for turn := 0; turn < a.MaxTurns; turn++ {
    if a.shouldUseSmartRouting() {
        // Smart routing called every turn - inefficient!
        conversationContext := a.buildConversationContext(messages)
        filteredTools, err := a.filterToolsByRelevance(ctx, conversationContext)
        // ... tool filtering logic
    }
}
```

**After (Fixed - Once at Start)**:
```go
// 🎯 SMART ROUTING INITIALIZATION - Run ONCE at conversation start
if a.shouldUseSmartRouting() {
    conversationContext := a.buildConversationContext(messages)
    filteredTools, err := a.filterToolsByRelevance(ctx, conversationContext)
    a.filteredTools = filteredTools // Store for entire conversation
} else {
    a.filteredTools = a.Tools // Use all tools
}

// In conversation loop - use pre-filtered tools
for turn := 0; turn < a.MaxTurns; turn++ {
    opts = append(opts, llms.WithTools(a.filteredTools)) // Use stored tools
}
```

### **Benefits of These Fixes**
1. **🎯 Better Tool Selection**: Smart routing now has complete conversation context
2. **📝 No Information Loss**: Full planning instructions and context preserved
3. **🔍 Smarter Decisions**: LLM understands tool capabilities, not just names
4. **⚡ Universal**: Works for any agent type or conversation pattern
5. **📊 Rich Context**: Tool descriptions provide semantic understanding
6. **🚀 Performance**: Smart routing runs once instead of every turn
7. **💾 Efficiency**: No repeated LLM calls for tool selection
8. **🔄 Consistency**: Same tool set maintained throughout conversation

## 🚀 **Implementation Plan**

### **Phase 1: Foundation (Day 1)**
1. ✅ **Add agent configuration options** (smart routing flag, thresholds)
2. ✅ **Implement smart routing detection logic**
3. ✅ **Create basic structure for tool filtering**

### **Phase 2: Core Logic (Day 2)**
1. ✅ **Implement server relevance determination function**
2. ✅ **Create tool filtering by server logic**
3. ✅ **Implement lightweight LLM call for routing**

### **Phase 3: Integration (Day 3)**
1. ✅ **Integrate into conversation flow**
2. ✅ **Add comprehensive testing**
3. ✅ **Update documentation and examples**

### **Phase 4: Testing & Validation**
1. ✅ **Unit test coverage**
2. ✅ **Integration testing**
3. ✅ **Performance validation**
4. ✅ **Fallback testing**

## 🔍 **Files to Modify**

### **Primary Files**
- `agent_go/pkg/mcpagent/agent.go` - Add smart routing configuration and logic
- `agent_go/pkg/mcpagent/conversation.go` - Integrate smart routing into conversation flow
- `agent_go/pkg/mcpagent/smart_routing.go` - **NEW FILE** - Core smart routing implementation

### **Supporting Files**
- `agent_go/pkg/mcpagent/events.go` - Add smart routing events
- `agent_go/pkg/mcpagent/prompt/smart_routing.go` - **NEW FILE** - Smart routing prompts
- `agent_go/pkg/mcpagent/smart_routing_test.go` - **NEW FILE** - Comprehensive testing

### **Configuration Files**
- `agent_go/.env.example` - Add smart routing environment variables
- `agent_go/configs/` - Add smart routing configuration examples

## 📍 **Specific Code Locations & Implementation Details**

### **1. `agent_go/pkg/mcpagent/agent.go` - Agent Configuration**
```go
// Add to Agent struct (around line 132)
type Agent struct {
    // ... existing fields ...
    EnableSmartRouting bool
    SmartRoutingThreshold struct {
        MaxTools    int
        MaxServers  int
    }
}

// Add new agent option (around line 101)
func WithSmartRouting(enabled bool) AgentOption {
    return func(a *Agent) {
        a.EnableSmartRouting = enabled
    }
}

func WithSmartRoutingThresholds(maxTools, maxServers int) AgentOption {
    return func(a *Agent) {
        a.SmartRoutingThreshold.MaxTools = maxTools
        a.SmartRoutingThreshold.MaxServers = maxServers
    }
}

// Update NewAgent constructor (around line 250)
ag.SmartRoutingThreshold.MaxTools = 30
ag.SmartRoutingThreshold.MaxServers = 4
ag.EnableSmartRouting = true // Default to enabled
```

### **2. `agent_go/pkg/mcpagent/conversation.go` - Integration Point**
```go
// Update around line 343 where tools are added to LLM
if a.shouldUseSmartRouting() {
    // Get the full conversation history for context
    conversationContext := a.buildConversationContext(messages)
    
    filteredTools, err := a.filterToolsByRelevance(ctx, conversationContext)
    if err != nil {
        logger.Warnf("Smart routing failed, using all tools: %v", err)
        filteredTools = a.Tools // Fallback to all tools
    }
    
    opts = append(opts, llms.WithTools(filteredTools))
    logger.Infof("Smart routing enabled: using %d filtered tools out of %d total", 
                 len(filteredTools), len(a.Tools))
} else {
    opts = append(opts, llms.WithTools(a.Tools))
}
```

### **3. `agent_go/pkg/mcpagent/smart_routing.go` - NEW FILE (Complete Implementation)**
```go
// Complete new file with smart routing logic
package mcpagent

import (
    "context"
    "fmt"
    "strings"
    "time"
    
    "github.com/tmc/langchaingo/llms"
)

// Smart routing detection
func (a *Agent) shouldUseSmartRouting() bool {
    return a.EnableSmartRouting && 
           len(a.Tools) > a.SmartRoutingThreshold.MaxTools &&
           len(a.Clients) > a.SmartRoutingThreshold.MaxServers
}

// Build conversation context for smart routing
func (a *Agent) buildConversationContext(messages []llms.MessageContent) string {
    var contextBuilder strings.Builder
    
    // Always send FULL conversation context - no limits, no truncation
    // This ensures smart routing has complete information for proper tool selection
    contextBuilder.WriteString("FULL CONVERSATION CONTEXT:\n")
    
    for i := 0; i < len(messages); i++ {
        msg := messages[i]
        if msg.Role == llms.ChatMessageTypeHuman {
            content := a.extractTextContent(msg)
            contextBuilder.WriteString(fmt.Sprintf("User: %s\n", content))
        } else if msg.Role == llms.ChatMessageTypeAI {
            content := a.extractTextContent(msg)
            contextBuilder.WriteString(fmt.Sprintf("Assistant: %s\n", content))
        }
    }
    
    return contextBuilder.String()
}

// Tool filtering by relevance
func (a *Agent) filterToolsByRelevance(ctx context.Context, conversationContext string) ([]llms.Tool, error) {
    relevantServers, err := a.determineRelevantServers(ctx, conversationContext)
    if err != nil {
        return nil, err
    }
    return a.filterToolsByServers(relevantServers), nil
}

// Determine relevant servers with conversation context
func (a *Agent) determineRelevantServers(ctx context.Context, conversationContext string) ([]string, error) {
    prompt := a.buildServerSelectionPrompt(conversationContext)
    return a.makeLightweightLLMCall(ctx, prompt) // Now returns []string directly
}

// Build server selection prompt with conversation context
func (a *Agent) buildServerSelectionPrompt(conversationContext string) string {
    var serverList strings.Builder
    serverList.WriteString("AVAILABLE MCP SERVERS:\n")
    
    for serverName, client := range a.Clients {
        if client != nil {
            // Count tools for this server
            toolCount := 0
            for toolName, server := range a.toolToServer {
                if server == serverName {
                    toolCount++
                }
            }
            
            // Get sample tool names for context
            var sampleTools []string
            for toolName, server := range a.toolToServer {
                if server == serverName && len(sampleTools) < 3 {
                    sampleTools = append(sampleTools, toolName)
                }
            }
            
            serverList.WriteString(fmt.Sprintf("- %s: %d tools (%s)\n", 
                serverName, toolCount, strings.Join(sampleTools, ", ")))
        }
    }
    
    return fmt.Sprintf(`You are a tool routing assistant. Based on the user's query and conversation context, determine which MCP servers are most relevant.

%s

CONVERSATION CONTEXT:
%s

INSTRUCTIONS:
1. Analyze the conversation context to understand what the user is trying to accomplish
2. Identify which MCP servers contain tools that would be most helpful
3. Return ONLY the server names that are relevant in the relevant_servers array
4. Be selective - only include servers that are clearly needed
5. If in doubt, prefer MORE servers over fewer (better to have tools available)
6. Consider the full conversation flow, not just the last message
7. Include servers that might be needed for follow-up questions
8. When uncertain, err on the side of including more servers
9. Provide brief reasoning in the reasoning field

RESPONSE FORMAT: JSON with relevant_servers array and reasoning field

AVAILABLE SERVERS:`, serverList.String(), conversationContext)
}

// Make lightweight LLM call for server selection with structured output
func (a *Agent) makeLightweightLLMCall(ctx context.Context, prompt string) ([]string, error) {
    messages := []llms.MessageContent{
        {
            Role:  llms.ChatMessageTypeSystem,
            Parts: []llms.ContentPart{llms.TextContent{Text: "You are a tool routing assistant. Always respond with valid JSON."}},
        },
        {
            Role:  llms.ChatMessageTypeHuman,
            Parts: []llms.ContentPart{llms.TextContent{Text: prompt}},
        },
    }
    
    // Define the expected JSON schema for structured output
    schema := map[string]interface{}{
        "type": "object",
        "properties": map[string]interface{}{
            "relevant_servers": map[string]interface{}{
                "type": "array",
                "items": map[string]interface{}{
                    "type": "string",
                },
                "description": "Array of relevant MCP server names",
            },
            "reasoning": map[string]interface{}{
                "type": "string",
                "description": "Brief explanation of why these servers were selected",
            },
        },
        "required": []string{"relevant_servers"},
    }
    
    opts := []llms.CallOption{
        llms.WithTemperature(0.1),
        llms.WithMaxTokens(300),
        llms.WithStructuredOutput(schema), // Use structured output for reliable parsing
    }
    
    response, err := a.LLM.GenerateContent(ctx, messages, opts...)
    if err != nil {
        return nil, err
    }
    
    // Parse the structured response
    return a.parseStructuredServerResponse(response)
}

// Parse structured server selection response
func (a *Agent) parseStructuredServerResponse(response *llms.ContentResponse) ([]string, error) {
    // Extract the structured content
    if len(response.Choices) == 0 {
        return nil, fmt.Errorf("no response choices")
    }
    
    choice := response.Choices[0]
    if len(choice.Content.Parts) == 0 {
        return nil, fmt.Errorf("no content parts in response")
    }
    
    // Handle structured output (JSON)
    for _, part := range choice.Content.Parts {
        if jsonPart, ok := part.(llms.JSONContent); ok {
            return a.parseJSONServerResponse(jsonPart.Data)
        }
    }
    
    // Fallback to text parsing if structured output fails
    if len(choice.Content.Parts) > 0 {
        if textPart, ok := choice.Content.Parts[0].(llms.TextContent); ok {
            return a.parseTextServerResponse(textPart.Text)
        }
    }
    
    return nil, fmt.Errorf("unable to parse response content")
}

// Parse JSON server response
func (a *Agent) parseJSONServerResponse(data interface{}) ([]string, error) {
    // Convert data to map for easy access
    dataMap, ok := data.(map[string]interface{})
    if !ok {
        return nil, fmt.Errorf("invalid JSON structure")
    }
    
    // Extract relevant_servers array
    serversInterface, exists := dataMap["relevant_servers"]
    if !exists {
        return nil, fmt.Errorf("missing 'relevant_servers' field in response")
    }
    
    serversArray, ok := serversInterface.([]interface{})
    if !ok {
        return nil, fmt.Errorf("'relevant_servers' is not an array")
    }
    
    // Convert to string slice
    var servers []string
    for _, server := range serversArray {
        if serverStr, ok := server.(string); ok {
            serverStr = strings.TrimSpace(serverStr)
            if serverStr != "" {
                servers = append(servers, serverStr)
            }
        }
    }
    
    return servers, nil
}

// Fallback text parsing (for compatibility)
func (a *Agent) parseTextServerResponse(response string) ([]string, error) {
    // Clean up response and extract server names
    response = strings.TrimSpace(response)
    response = strings.TrimSuffix(response, ".")
    
    // Split by comma and clean up each server name
    serverNames := strings.Split(response, ",")
    var cleanServers []string
    
    for _, server := range serverNames {
        server = strings.TrimSpace(server)
        if server != "" {
            cleanServers = append(cleanServers, server)
        }
    }
    
    return cleanServers, nil
}

// Filter tools by server
func (a *Agent) filterToolsByServers(relevantServers []string) []llms.Tool {
    var filteredTools []llms.Tool
    
    for _, tool := range a.Tools {
        if serverName, exists := a.toolToServer[tool.Function.Name]; exists {
            for _, relevantServer := range relevantServers {
                if serverName == relevantServer {
                    filteredTools = append(filteredTools, tool)
                    break
                }
            }
        }
    }
    
    return filteredTools
}

// Helper function to extract text content
func (a *Agent) extractTextContent(msg llms.MessageContent) string {
    var textParts []string
    for _, part := range msg.Parts {
        if textPart, ok := part.(llms.TextContent); ok {
            textParts = append(textParts, textPart.Text)
        }
    }
    return strings.Join(textParts, " ")
}

// Getter and setter methods for smart routing configuration
func (a *Agent) IsSmartRoutingEnabled() bool {
    return a.EnableSmartRouting
}

func (a *Agent) SetSmartRouting(enabled bool) {
    a.EnableSmartRouting = enabled
}

func (a *Agent) GetSmartRoutingThresholds() struct {
    MaxTools    int
    MaxServers  int
} {
    return a.SmartRoutingThreshold
}

func (a *Agent) SetSmartRoutingThresholds(maxTools, maxServers int) {
    a.SmartRoutingThreshold.MaxTools = maxTools
    a.SmartRoutingThreshold.MaxServers = maxServers
}

func (a *Agent) ShouldUseSmartRouting() bool {
    return a.shouldUseSmartRouting()
}

### **4. `agent_go/pkg/agentwrapper/llm_agent.go` - LLM Agent Wrapper Integration**
```go
// Add to LLMAgentConfig struct (around line 50)
type LLMAgentConfig struct {
    Name               string
    ServerName         string
    ConfigPath         string
    Provider           llm.Provider
    ModelID            string
    Temperature        float64
    ToolChoice         string
    MaxTurns           int
    StreamingChunkSize int
    Timeout            time.Duration
    ToolTimeout        time.Duration
    AgentMode          mcpagent.AgentMode
    
    // NEW: Smart routing configuration
    EnableSmartRouting bool
    SmartRoutingThreshold struct {
        MaxTools    int
        MaxServers  int
    }
}

// Update NewLLMAgentWrapperWithTrace (around line 120)
func NewLLMAgentWrapperWithTrace(ctx context.Context, config LLMAgentConfig, tracer observability.Tracer, mainTraceID observability.TraceID, logger utils.ExtendedLogger) (*LLMAgentWrapper, error) {
    // ... existing code ...
    
    // Initialize the underlying MCP agent with smart routing options
    var agent *mcpagent.Agent
    if config.AgentMode == mcpagent.ReActAgent {
        agent, err = mcpagent.NewReActAgent(
            ctx, llm, config.ServerName, config.ConfigPath, config.ModelID,
            tracer, traceID, logger,
            mcpagent.WithTemperature(config.Temperature),
            mcpagent.WithToolChoice(config.ToolChoice),
            mcpagent.WithMaxTurns(config.MaxTurns),
            mcpagent.WithToolTimeout(config.ToolTimeout),
            // NEW: Add smart routing options
            mcpagent.WithSmartRouting(config.EnableSmartRouting),
            mcpagent.WithSmartRoutingThresholds(
                config.SmartRoutingThreshold.MaxTools,
                config.SmartRoutingThreshold.MaxServers,
            ),
        )
    } else {
        agent, err = mcpagent.NewSimpleAgent(
            ctx, llm, config.ServerName, config.ConfigPath, config.ModelID,
            tracer, traceID, logger,
            mcpagent.WithTemperature(config.Temperature),
            mcpagent.WithToolChoice(config.ToolChoice),
            mcpagent.WithMaxTurns(config.MaxTurns),
            mcpagent.WithToolTimeout(config.ToolTimeout),
            // NEW: Add smart routing options
            mcpagent.WithSmartRouting(config.EnableSmartRouting),
            mcpagent.WithSmartRoutingThresholds(
                config.SmartRoutingThreshold.MaxTools,
                config.SmartRoutingThreshold.MaxServers,
            ),
        )
    }
    
    // ... rest of existing code ...
}

// Add smart routing getter methods
func (w *LLMAgentWrapper) IsSmartRoutingEnabled() bool {
    w.mu.RLock()
    defer w.mu.RUnlock()
    
    if w.closed || w.agent == nil {
        return false
    }
    
    // Access the underlying agent's smart routing status
    // This requires adding a getter method to the Agent struct
    return w.agent.IsSmartRoutingEnabled()
}

func (w *LLMAgentWrapper) GetSmartRoutingStats() map[string]interface{} {
    w.mu.RLock()
    defer w.mu.RUnlock()
    
    if w.closed || w.agent == nil {
        return map[string]interface{}{"error": "Agent is closed"}
    }
    
    // Return smart routing statistics
    return map[string]interface{}{
        "smart_routing_enabled": w.agent.IsSmartRoutingEnabled(),
        "total_tools":           len(w.agent.Tools),
        "total_servers":         len(w.agent.Clients),
        "thresholds": map[string]interface{}{
            "max_tools":    w.agent.GetSmartRoutingThresholds().MaxTools,
            "max_servers":  w.agent.GetSmartRoutingThresholds().MaxServers,
        },
    }
}
```

### **5. `agent_go/pkg/external/` - External Agent Interface Integration**
```go
// Add to agent_go/pkg/external/agent.go - ExternalAgent struct
type ExternalAgent struct {
    // ... existing fields ...
    
    // NEW: Smart routing configuration
    EnableSmartRouting bool
    SmartRoutingThreshold struct {
        MaxTools    int
        MaxServers  int
    }
}

// Add smart routing configuration to agent creation
func NewExternalAgent(ctx context.Context, config ExternalAgentConfig, logger utils.ExtendedLogger) (*ExternalAgent, error) {
    // ... existing code ...
    
    // Initialize MCP agent with smart routing
    agent, err := mcpagent.NewAgent(
        ctx, llm, config.ServerName, config.ConfigPath, config.ModelID,
        tracer, traceID, logger,
        mcpagent.WithMode(config.AgentMode),
        mcpagent.WithTemperature(config.Temperature),
        mcpagent.WithMaxTurns(config.MaxTurns),
        mcpagent.WithToolChoice(config.ToolChoice),
        // NEW: Add smart routing options
        mcpagent.WithSmartRouting(config.EnableSmartRouting),
        mcpagent.WithSmartRoutingThresholds(
            config.SmartRoutingThreshold.MaxTools,
            config.SmartRoutingThreshold.MaxServers,
        ),
    )
    
    // ... rest of existing code ...
}

// Add smart routing methods to ExternalAgent
func (ea *ExternalAgent) EnableSmartRouting(enabled bool) {
    ea.mu.Lock()
    defer ea.mu.Unlock()
    ea.EnableSmartRouting = enabled
    
    // Update underlying agent if available
    if ea.agent != nil {
        // This requires adding a setter method to the Agent struct
        ea.agent.SetSmartRouting(enabled)
    }
}

func (ea *ExternalAgent) SetSmartRoutingThresholds(maxTools, maxServers int) {
    ea.mu.Lock()
    defer ea.mu.Unlock()
    ea.SmartRoutingThreshold.MaxTools = maxTools
    ea.SmartRoutingThreshold.MaxServers = maxServers
    
    // Update underlying agent if available
    if ea.agent != nil {
        // This requires adding a setter method to the Agent struct
        ea.agent.SetSmartRoutingThresholds(maxTools, maxServers)
    }
}

func (ea *ExternalAgent) GetSmartRoutingStatus() map[string]interface{} {
    ea.mu.RLock()
    defer ea.mu.RUnlock()
    
    if ea.agent == nil {
        return map[string]interface{}{"error": "Agent not initialized"}
    }
    
    return map[string]interface{}{
        "smart_routing_enabled": ea.EnableSmartRouting,
        "thresholds": map[string]interface{}{
            "max_tools":    ea.SmartRoutingThreshold.MaxTools,
            "max_servers":  ea.SmartRoutingThreshold.MaxServers,
        },
        "current_status": map[string]interface{}{
            "total_tools":   len(ea.agent.Tools),
            "total_servers": len(ea.agent.Clients),
            "should_use_smart_routing": ea.agent.ShouldUseSmartRouting(),
        },
    }
}
```

## ⚠️ **Risks & Mitigation**

### **Risk 1: Smart Routing Failure**
- **Risk**: LLM fails to determine relevant servers
- **Mitigation**: Always fallback to all tools, log warnings

### **Risk 2: Performance Degradation**
- **Risk**: Additional LLM call adds latency
- **Mitigation**: Use minimal context, lower token limits, cache results

### **Risk 3: Incorrect Tool Filtering**
- **Risk**: Relevant tools are filtered out
- **Mitigation**: Conservative filtering, user feedback, monitoring

### **Risk 4: Configuration Complexity**
- **Risk**: Too many options confuse users
- **Mitigation**: Sensible defaults, clear documentation, examples

## 📈 **Success Criteria**

### **Functional Requirements**
- ✅ Smart routing works when tools > 30 AND servers > 4
- ✅ Tool filtering reduces tool count by at least 30%
- ✅ Fallback to all tools works when smart routing fails
- ✅ No breaking changes to existing functionality

### **Performance Requirements**
- ✅ Smart routing adds <100ms latency
- ✅ Token usage reduced by at least 20%
- ✅ Response time improved by at least 15%

### **Quality Requirements**
- ✅ 90%+ test coverage for new functionality
- ✅ Comprehensive error handling and logging
- ✅ Clear documentation and examples
- ✅ Performance monitoring and metrics

## 🔄 **Future Enhancements**

### **Phase 2 Features**
- **Caching**: Cache smart routing decisions for similar queries
- **Learning**: Improve routing based on user feedback
- **Analytics**: Track routing effectiveness over time
- **Custom Prompts**: Allow users to customize routing prompts

### **Advanced Routing**
- **Multi-Level Filtering**: Tool-level filtering in addition to server-level
- **Query Classification**: Use ML to classify query types
- **Dynamic Thresholds**: Adjust thresholds based on performance
- **User Preferences**: Remember user's preferred tool sets

## 📚 **References**

### **Related Documentation**
- [Cache MCP Server Architecture](./cache-mcp-server-architecture-and-implementation-2025-01-27.md)
- [MCP Agent System Overview](./mcp-agent-system-overview.md)
- [Agent External Refactor](./agent-external-refactor.md)

### **Technical References**
- [LangChain Go Tools](https://github.com/tmc/langchaingo)
- [MCP Go Library](https://github.com/mark3labs/mcp-go)
- [LLM Function Calling Best Practices](https://platform.openai.com/docs/guides/function-calling)

---

**Next Steps**: Begin implementation with Phase 1 (Foundation) - adding agent configuration options and smart routing detection logic.

---

## 🎯 **Implementation Summary & Key Features**

### **✅ What This Implementation Provides**
1. **Smart Tool Filtering**: Automatically filters tools when >30 tools and >4 servers
2. **Full Conversation Context**: Uses last 8 messages for intelligent routing decisions
3. **Conservative Approach**: When in doubt, includes more servers (not fewer)
4. **Event Integration**: Proper event emission following types-sync-design.md patterns
5. **Fallback Safety**: Always falls back to all tools if smart routing fails
6. **Performance Optimization**: Lightweight LLM call with minimal token usage
7. **Structured Output**: JSON responses for reliable parsing and rich information
8. **Reasoning Capture**: LLM explains why specific servers were selected

### **🔧 Key Implementation Files**
1. **`agent_go/pkg/mcpagent/agent.go`** - Add configuration options and struct fields
2. **`agent_go/pkg/mcpagent/conversation.go`** - Integrate smart routing into conversation flow  
3. **`agent_go/pkg/mcpagent/smart_routing.go`** - **NEW FILE** - Complete smart routing logic
4. **`agent_go/pkg/mcpagent/events.go`** - Add smart routing events
5. **`agent_go/pkg/agentwrapper/llm_agent.go`** - Add smart routing support to LLM agent wrapper
6. **`agent_go/pkg/external/`** - Add smart routing support to external agent interface

### **🚀 Benefits for Users**
- **Faster Responses**: Reduced tool overload leads to better LLM performance
- **Better Tool Selection**: LLM focuses on relevant tools for the query
- **Improved Accuracy**: Context-aware routing based on full conversation
- **Scalability**: Handles large numbers of tools efficiently
- **Debugging**: Complete observability through event system

### **📊 Event System Integration**
- **Smart Routing Events**: `smart_routing_start` and `smart_routing_end` events
- **Frontend Visibility**: Events automatically appear in EventDispatcher
- **Performance Metrics**: Track routing success rates and latency
- **Debugging Support**: Understand routing decisions and server selection

**Ready to implement!** 🚀
