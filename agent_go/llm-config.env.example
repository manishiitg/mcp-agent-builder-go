# LLM Configuration Environment Variables
# This file documents all environment variables used for LLM configuration
# Copy this to your .env file and customize the values

# =============================================================================
# PRIMARY LLM CONFIGURATION
# =============================================================================

# Primary LLM provider (openrouter, bedrock, openai)
AGENT_PROVIDER=openrouter

# Primary LLM model ID
AGENT_MODEL=x-ai/grok-code-fast-1

# =============================================================================
# OPENROUTER CONFIGURATION
# =============================================================================

# OpenRouter fallback models (comma-separated)
OPENROUTER_FALLBACK_MODELS=x-ai/grok-code-fast-1,openai/gpt-5-mini

# OpenRouter cross-provider fallback configuration
OPENROUTER_CROSS_FALLBACK_PROVIDER=openai
OPENROUTER_CROSS_FALLBACK_MODELS=gpt-5-mini

# =============================================================================
# BEDROCK CONFIGURATION
# =============================================================================

# Bedrock model ID
BEDROCK_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0

# Bedrock fallback models (comma-separated)
BEDROCK_FALLBACK_MODELS=us.anthropic.claude-3-7-sonnet-20250219-v1:0

# Bedrock region
BEDROCK_REGION=us-east-1

# Bedrock cross-provider fallback configuration
BEDROCK_CROSS_FALLBACK_PROVIDER=openrouter
BEDROCK_CROSS_FALLBACK_MODELS=x-ai/grok-code-fast-1,openai/gpt-4o-mini

# =============================================================================
# OPENAI CONFIGURATION
# =============================================================================

# OpenAI model ID
OPENAI_MODEL=gpt-5-mini

# OpenAI fallback models (comma-separated)
OPENAI_FALLBACK_MODELS=gpt-4o-mini,gpt-4-turbo

# OpenAI cross-provider fallback configuration
OPENAI_CROSS_FALLBACK_PROVIDER=openrouter
OPENAI_CROSS_FALLBACK_MODELS=x-ai/grok-code-fast-1

# =============================================================================
# API KEYS (Set these in your environment or .env file)
# =============================================================================

# OpenRouter API Key (will be prefilled in UI for testing)
OPENROUTER_API_KEY=sk-or-...

# Available OpenRouter models (comma-separated)
OPENROUTER_AVAILABLE_MODELS=x-ai/grok-code-fast-1,openai/gpt-5-mini,anthropic/claude-3.5-sonnet,meta-llama/llama-3.1-405b-instruct

# OpenAI API Key (will be prefilled in UI for testing)
OPENAI_API_KEY=sk-...

# Available OpenAI models (comma-separated)
OPENAI_AVAILABLE_MODELS=gpt-5-mini,gpt-4o,gpt-4o-mini,gpt-3.5-turbo

# AWS Credentials for Bedrock
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=us-east-1

# Available Bedrock models (comma-separated)
BEDROCK_AVAILABLE_MODELS=global.anthropic.claude-sonnet-4-5-20250929-v1:0,us.anthropic.claude-sonnet-4-20250514-v1:0,us.anthropic.claude-3-7-sonnet-20250219-v1:0

# =============================================================================
# NOTES
# =============================================================================

# 1. All model names and configurations are now driven by environment variables
# 2. No hardcoded values in frontend or backend code
# 3. Fallback models are comma-separated lists
# 4. Cross-provider fallback allows switching to different providers if primary fails
# 5. API keys from environment variables will be prefilled in the UI for testing
# 6. Empty values will result in empty arrays/undefined in the API response
# 7. The frontend will load these defaults automatically on startup
# 8. API key validation is handled by the backend for security
